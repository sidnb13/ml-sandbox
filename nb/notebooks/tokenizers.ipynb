{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sidbaskaran/miniconda3/envs/torchml/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1985]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.encode(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<|endoftext|>': 100257,\n",
       " '<|fim_prefix|>': 100258,\n",
       " '<|fim_middle|>': 100259,\n",
       " '<|fim_suffix|>': 100260,\n",
       " '<|endofprompt|>': 100276}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding._special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wikitext (/Users/sidbaskaran/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Loading cached processed dataset at /Users/sidbaskaran/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-82e63c6c3fde2311.arrow\n"
     ]
    }
   ],
   "source": [
    "raw_dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"train\")\n",
    "raw_dataset = raw_dataset.filter(lambda x: len(x[\"text\"]) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/sidbaskaran/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-45ce7928739699e8.arrow\n"
     ]
    }
   ],
   "source": [
    "raw_dataset = raw_dataset.map(lambda x: {\"ids\": encoding.encode(x[\"text\"])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = raw_dataset.remove_columns([\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = raw_dataset.to_dict()[\"ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100276"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding._special_tokens[\"<|endofprompt|>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tokens)):\n",
    "    if len(tokens[i]) > max_sequence_length:\n",
    "        extra_seq = tokens[i][max_sequence_length:]\n",
    "        tokens[i] = torch.tensor(tokens[i][:max_sequence_length])\n",
    "        while len(extra_seq) > max_sequence_length:\n",
    "            padded_tokens = extra_seq[:max_sequence_length]\n",
    "            padded_tokens = F.pad(\n",
    "                torch.tensor(padded_tokens),\n",
    "                (0, max_sequence_length - len(padded_tokens)),\n",
    "                value=-1,\n",
    "            )\n",
    "            tokens.append(padded_tokens)\n",
    "            extra_seq = extra_seq[max_sequence_length:]\n",
    "    else:\n",
    "        tokens[i] = F.pad(\n",
    "            torch.tensor(tokens[i]), (0, max_sequence_length - len(tokens[i])), value=-1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.stack(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23800, 256])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1, 1, 1, 1, 1, 0, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.expand(x.size(0), 8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(x).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[168], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mDecoderBlock\u001b[39;00m(nn\u001b[39m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m      3\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m      4\u001b[0m         num_heads: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m         return_attn_weights: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m     ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_heads: int,\n",
    "        embed_dim: int,\n",
    "        block_size: int,\n",
    "        attn_dropout: float,\n",
    "        layer_dropout: float,\n",
    "        return_attn_weights: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.block_size = block_size\n",
    "        self.multihead_attention = nn.MultiheadAttention(\n",
    "            embed_dim, num_heads, dropout=attn_dropout, batch_first=True\n",
    "        )\n",
    "        self.ln1 = nn.LayerNorm(embed_dim)\n",
    "        # positionwise FFN\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim * 4),\n",
    "            nn.GELU(),  # as in original GPT\n",
    "            nn.Linear(embed_dim * 4, embed_dim),\n",
    "            nn.Dropout(layer_dropout),\n",
    "        )\n",
    "        self.ln2 = nn.LayerNorm(embed_dim)\n",
    "        self.return_attn_weights = return_attn_weights\n",
    "\n",
    "    def forward(\n",
    "        self, x: torch.Tensor, attn_mask: torch.Tensor\n",
    "    ) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        # self attention and residual, -1 denotes padding\n",
    "        causal_mask = torch.tril(attn_mask).squeeze().to(x.device)\n",
    "        attn_out, attn_weights = self.multihead_attention(\n",
    "            x, x, x, attn_mask=causal_mask\n",
    "        )\n",
    "        x = self.ln1(x + attn_out)\n",
    "        # feed forward and residual\n",
    "        x = self.ln2(x + self.feed_forward(x))\n",
    "\n",
    "        if self.return_attn_weights:\n",
    "            return x, attn_weights\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
